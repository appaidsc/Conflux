# ═══════════════════════════════════════════════════════════════
# CONFLUENCE MCP SERVER - ENVIRONMENT CONFIGURATION
# ═══════════════════════════════════════════════════════════════
# Copy this file to .env and fill in your values
# DO NOT commit .env to version control!

# ═══════════════════════════════════════════════════════════════
# CONFLUENCE CONFIGURATION
# ═══════════════════════════════════════════════════════════════
CONFLUENCE_BASE_URL=https://your-company.atlassian.net/wiki
CONFLUENCE_USERNAME=your-email@company.com
CONFLUENCE_API_TOKEN=your-personal-access-token
CONFLUENCE_SPACE_KEY=DOCS

# ═══════════════════════════════════════════════════════════════
# QDRANT CONFIGURATION
# ═══════════════════════════════════════════════════════════════
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION=confluence_pages
QDRANT_API_KEY=

# ═══════════════════════════════════════════════════════════════
# LLM CONFIGURATION
# ═══════════════════════════════════════════════════════════════
LLM_PROVIDER=lm_studio
LLM_BASE_URL=http://localhost:1234/v1
LLM_API_KEY=
LLM_MODEL=qwen2.5-7b-instruct
LLM_TIMEOUT_MS=30000

# ═══════════════════════════════════════════════════════════════
# EMBEDDING MODELS
# ═══════════════════════════════════════════════════════════════
EMBEDDING_MODEL_DENSE=BAAI/bge-base-en-v1.5
EMBEDDING_MODEL_SPARSE=prithivida/Splade_PP_en_v1
EMBEDDING_BATCH_SIZE=32
MODELS_CACHE_DIR=./models_cache

# ═══════════════════════════════════════════════════════════════
# MCP SERVER
# ═══════════════════════════════════════════════════════════════
MCP_TRANSPORT=sse
MCP_PORT=8080
MCP_HOST=0.0.0.0

# ═══════════════════════════════════════════════════════════════
# PIPELINE SETTINGS
# ═══════════════════════════════════════════════════════════════
MAX_PAGES_TO_CRAWL=3000
PIPELINE_CONCURRENCY=10
ENABLE_LLM_SUMMARIES=true

# Background LLM Summary Enhancement (Progressive Quality)
# When enabled, initial indexing uses fast extractive summaries
# A background worker then generates LLM summaries and re-embeds
# This improves search quality over time without slowing initial sync
BACKGROUND_LLM_SUMMARIES=true
LLM_SUMMARY_BATCH_SIZE=5

# ═══════════════════════════════════════════════════════════════
# CACHING
# ═══════════════════════════════════════════════════════════════
CACHE_ENABLED=true
CACHE_TTL_QUERY_SECONDS=300
CACHE_TTL_CONTENT_SECONDS=900
CACHE_MAX_SIZE_MB=1024

# ═══════════════════════════════════════════════════════════════
# LOGGING
# ═══════════════════════════════════════════════════════════════
LOG_LEVEL=INFO
LOG_FORMAT=json
